{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt8sW38dnqSR"
      },
      "source": [
        "# Read Me\n",
        "\n",
        "For the easiest experience of running this .ipynb, please use Google Colab. All that needs to be done is to upload the included .txt files that are saved inside the \"data\" file within this .zip. Once the .ipynb has been uploaded, simply go to \"Runtime\" and select \"Run all\", and the model will be ready in approxametly 1 hour.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhD6zvitkKwG"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "import tensorflow as tf\n",
        "import numpy as pn\n",
        "import sklearn\n",
        "import matplotlib as mat\n",
        "import torch\n",
        "import math\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from numpy import array, asarray, zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kVdgIxmwcgV",
        "outputId": "6ea8553e-00d7-4048-c9cb-2fac741b03cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "1.21.5\n",
            "3.2.2\n",
            "1.0.2\n",
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(mat.__version__)\n",
        "print(sklearn.__version__)\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTxo0PE9kMl_"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "LSTM_NODES =256\n",
        "NUM_POLYS = 20000\n",
        "MAX_POLY_LENGTH = 50\n",
        "MAX_NUM_CHARS = 20000\n",
        "EMBEDDING_SIZE = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "403oO513mVI0"
      },
      "outputs": [],
      "source": [
        "''' This showed me all the characters within the dataset\n",
        "with open('dataset.txt', 'r') as dataset:\n",
        "  all_chars = set(dataset.read().replace('\\n', ''))\n",
        "\n",
        "dataset.close()\n",
        "\n",
        "print(all_chars)\n",
        "'''\n",
        "nums = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9') #numbers\n",
        "ops = ('(', ')', '+', '-', '*') #operators\n",
        "vars = ('h', 'n', 'o', 's', 'c', 'z', 'a', 'y', 't', 'x', 'j', 'k') #variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHRtmGXKk1K_"
      },
      "outputs": [],
      "source": [
        "with open('dataset.txt', 'r') as dataset:\n",
        "  raw = dataset.readlines()\n",
        "\n",
        "factorized = []\n",
        "expanded = []\n",
        "\n",
        "for i, poly in enumerate(raw):\n",
        "  raw[i] = raw[i].strip()\n",
        "  equal = raw[i].find('=')\n",
        "  factorized.append(raw[i][0:equal])\n",
        "  expanded.append(raw[i][equal+1:])\n",
        "\n",
        "dataset.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfB_MHh2kRzR"
      },
      "outputs": [],
      "source": [
        "def clean_data(data):\n",
        "  data_clean = []\n",
        "  for i, poly in enumerate(data):\n",
        "    factor = \"\"\n",
        "    j = 0\n",
        "    while j < len(poly) - 1:\n",
        "\n",
        "      if poly[j] in nums:\n",
        "        if poly[j+1] not in nums:\n",
        "          factor += poly[j] + ' '\n",
        "        else:\n",
        "          factor += poly[j]\n",
        "      \n",
        "      elif poly[j] in ops:\n",
        "        if poly[j] is '*' and poly[j+1] is '*':\n",
        "          factor += poly[j] + '* '\n",
        "          j += 1\n",
        "        else:\n",
        "          factor += poly[j] + ' '\n",
        "      \n",
        "      elif poly[j] in vars:\n",
        "        if poly[j] is 's' and poly[j+1] is 'i':\n",
        "          factor += 'sin '\n",
        "          j += 2\n",
        "        elif poly[j] is 'c' and poly[j+1] is 'o':\n",
        "          factor += 'cos '\n",
        "          j += 2\n",
        "        elif poly[j] is 't' and poly[j+1] is 'a':\n",
        "          factor += 'tan '\n",
        "          j += 2\n",
        "        else:\n",
        "          factor += 'x '\n",
        "      j += 1\n",
        "    if poly[-1] in vars:\n",
        "      factor += 'x'\n",
        "    else:\n",
        "      factor += poly[-1]\n",
        "    data_clean.append(factor)\n",
        "  return data_clean\n",
        "\n",
        "factors_clean = clean_data(factorized)\n",
        "expandeds_clean = clean_data(expanded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5blRndGdsGXb"
      },
      "outputs": [],
      "source": [
        "equal_pairs = []\n",
        "for i in range(len(factors_clean)):\n",
        "  equal_pairs.append([factors_clean[i], expandeds_clean[i]])\n",
        "\n",
        "#training: 80%, testing: 10%, validation: 10%\n",
        "pairs, test_pairs = train_test_split(equal_pairs, test_size = 0.2)\n",
        "validation_pairs, test_pairs = train_test_split(test_pairs, test_size = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMS4-49slD_Z"
      },
      "outputs": [],
      "source": [
        "input_polys = []\n",
        "output_polys = []\n",
        "output_polys_inputs = []\n",
        "\n",
        "count = 0\n",
        "for pair in pairs:\n",
        "  count += 1\n",
        "\n",
        "  if count > NUM_POLYS:\n",
        "    break\n",
        "\n",
        "  input_polys.append(pair[0])\n",
        "  output_polys.append(pair[1] + ' <eos>')\n",
        "  output_polys_inputs.append('<sos> ' + pair[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkNOkMCMoP2p"
      },
      "outputs": [],
      "source": [
        "input_tokenizer = Tokenizer(num_words=MAX_NUM_CHARS)\n",
        "input_tokenizer.fit_on_texts(input_polys)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_polys)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "\n",
        "max_input_len = max(len(poly) for poly in input_integer_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eX7CX6TrVDz"
      },
      "outputs": [],
      "source": [
        "output_tokenizer = Tokenizer(num_words=MAX_NUM_CHARS, filters='')\n",
        "output_tokenizer.fit_on_texts(output_polys + output_polys_inputs)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_polys)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_polys_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "\n",
        "num_chars_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(poly) for poly in output_input_integer_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDWTvLu1sKRb"
      },
      "outputs": [],
      "source": [
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uSZyXRRsZIY"
      },
      "outputs": [],
      "source": [
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoBqZAiCslMT"
      },
      "outputs": [],
      "source": [
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove = open('glove.6B.100d.txt', encoding='utf8')\n",
        "\n",
        "for line in glove:\n",
        "  records = line.split()\n",
        "  word = records[0]\n",
        "  vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "  embeddings_dictionary[word] = vector_dimensions\n",
        "glove.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9DQlFHnwjjk"
      },
      "outputs": [],
      "source": [
        "num_words = min(MAX_NUM_CHARS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = zeros((num_words, EMBEDDING_SIZE))\n",
        "\n",
        "for char, index in word2idx_inputs.items():\n",
        "  embedding_vector = embeddings_dictionary.get(char)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[index] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39oVPHfNxErX"
      },
      "outputs": [],
      "source": [
        "embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl5TaLxXxNjO"
      },
      "outputs": [],
      "source": [
        "decoder_targets_one_hot = np.zeros((len(input_polys), max_out_len, num_chars_output), dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9niaYcdxupx"
      },
      "outputs": [],
      "source": [
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "\n",
        "for i, d in enumerate(decoder_output_sequences):\n",
        "  for t, char in enumerate(d):\n",
        "    decoder_targets_one_hot[i, t, char] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuFN0R-Hys5Z"
      },
      "outputs": [],
      "source": [
        "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(LSTM_NODES, return_state=True)\n",
        "\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "encoder_states = [h, c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfnvxnxyzR4H"
      },
      "outputs": [],
      "source": [
        "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
        "\n",
        "decoder_embedding = Embedding(num_chars_output, LSTM_NODES)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ =decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjATL1ktz3hE"
      },
      "outputs": [],
      "source": [
        "decoder_dense = Dense(num_chars_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IseGC_uw0B8x"
      },
      "outputs": [],
      "source": [
        "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFmA04Az1gF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7663c9-701a-40d0-c2e7-594cb598a283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "282/282 [==============================] - 18s 35ms/step - loss: 1.0896 - accuracy: 0.7666 - val_loss: 0.7459 - val_accuracy: 0.8222\n",
            "Epoch 2/20\n",
            "282/282 [==============================] - 10s 34ms/step - loss: 0.6761 - accuracy: 0.8297 - val_loss: 0.6491 - val_accuracy: 0.8322\n",
            "Epoch 3/20\n",
            "282/282 [==============================] - 8s 30ms/step - loss: 0.5961 - accuracy: 0.8438 - val_loss: 0.5748 - val_accuracy: 0.8454\n",
            "Epoch 4/20\n",
            "282/282 [==============================] - 8s 30ms/step - loss: 0.5269 - accuracy: 0.8590 - val_loss: 0.5281 - val_accuracy: 0.8580\n",
            "Epoch 5/20\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.4758 - accuracy: 0.8697 - val_loss: 0.4805 - val_accuracy: 0.8650\n",
            "Epoch 6/20\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.4316 - accuracy: 0.8787 - val_loss: 0.4229 - val_accuracy: 0.8797\n",
            "Epoch 7/20\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.3884 - accuracy: 0.8880 - val_loss: 0.3930 - val_accuracy: 0.8866\n",
            "Epoch 8/20\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.3514 - accuracy: 0.8980 - val_loss: 0.3716 - val_accuracy: 0.8894\n",
            "Epoch 9/20\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.3194 - accuracy: 0.9068 - val_loss: 0.3409 - val_accuracy: 0.8971\n",
            "Epoch 10/20\n",
            "282/282 [==============================] - 9s 30ms/step - loss: 0.2925 - accuracy: 0.9138 - val_loss: 0.3111 - val_accuracy: 0.9080\n",
            "Epoch 11/20\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.2695 - accuracy: 0.9195 - val_loss: 0.2957 - val_accuracy: 0.9098\n",
            "Epoch 12/20\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.2513 - accuracy: 0.9246 - val_loss: 0.2871 - val_accuracy: 0.9122\n",
            "Epoch 13/20\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.2352 - accuracy: 0.9290 - val_loss: 0.2753 - val_accuracy: 0.9169\n",
            "Epoch 14/20\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.2213 - accuracy: 0.9321 - val_loss: 0.2601 - val_accuracy: 0.9207\n",
            "Epoch 15/20\n",
            "282/282 [==============================] - 7s 26ms/step - loss: 0.2082 - accuracy: 0.9356 - val_loss: 0.2540 - val_accuracy: 0.9212\n",
            "Epoch 16/20\n",
            "282/282 [==============================] - 7s 26ms/step - loss: 0.1969 - accuracy: 0.9376 - val_loss: 0.2445 - val_accuracy: 0.9217\n",
            "Epoch 17/20\n",
            "282/282 [==============================] - 7s 26ms/step - loss: 0.1872 - accuracy: 0.9407 - val_loss: 0.2416 - val_accuracy: 0.9235\n",
            "Epoch 18/20\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1791 - accuracy: 0.9420 - val_loss: 0.2463 - val_accuracy: 0.9223\n",
            "Epoch 19/20\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1714 - accuracy: 0.9441 - val_loss: 0.2433 - val_accuracy: 0.9228\n",
            "Epoch 20/20\n",
            "282/282 [==============================] - 7s 25ms/step - loss: 0.1641 - accuracy: 0.9462 - val_loss: 0.2405 - val_accuracy: 0.9231\n"
          ]
        }
      ],
      "source": [
        "r = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets_one_hot,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.1,\n",
        "    validation_data=(validation_pairs)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9x1wNou1j4J"
      },
      "outputs": [],
      "source": [
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlemiMBJ1mcD"
      },
      "outputs": [],
      "source": [
        "decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
        "decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEPMZYyb1oGM"
      },
      "outputs": [],
      "source": [
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8MVjc8C1p2E"
      },
      "outputs": [],
      "source": [
        "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jGBArbI1rXK"
      },
      "outputs": [],
      "source": [
        "decoder_states = [h, c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eavfxu5s1tEw"
      },
      "outputs": [],
      "source": [
        "decoder_model = Model(\n",
        "    [decoder_inputs_single] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckfJDyqKmR-V"
      },
      "outputs": [],
      "source": [
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4UaOZms128_"
      },
      "outputs": [],
      "source": [
        "def expand_poly(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_out_len):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeMRPjc36Vsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6aa96bc-6927-4494-8cc9-f826a6cf49c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input: ( x + 6 ) * ( 7 * x + 24 )\n",
            "Response: 7 * x ** 2 + 54 * x - 144\n"
          ]
        }
      ],
      "source": [
        "i = np.random.choice(len(input_polys))\n",
        "input_seq = encoder_input_sequences[i:i+1]\n",
        "translation = expand_poly(input_seq)\n",
        "print('-')\n",
        "print('Input:', input_polys[i])\n",
        "print('Response:', translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q8-0BUtBpMZ"
      },
      "outputs": [],
      "source": [
        "test_x = []\n",
        "test_y = []\n",
        "\n",
        "for i, pair in enumerate(test_pairs):\n",
        "  test_x.append(pair[0])\n",
        "  test_y.append(pair[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NCPMkoCBgl4"
      },
      "outputs": [],
      "source": [
        "test_tokenizer = Tokenizer(num_words=MAX_NUM_CHARS)\n",
        "test_tokenizer.fit_on_texts(test_x)\n",
        "test_integer_seq = input_tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "word2idx_test = test_tokenizer.word_index\n",
        "\n",
        "max_test_len = max(len(poly) for poly in test_integer_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq-tCM3uomfB"
      },
      "source": [
        "#Report\n",
        "\n",
        "When I initially saw the problem, one of the first thoughts of how to solve it would be something similar to a translation problem. I saw no difference between translating from english to french and translating from factorized to expanded form. With some research, I was able to determine that the NLP model that would be most applicable to this specific problem was the Seq2Seq model, as this is the most commonly used model in NLP problems. Seq2Seq is a type of Recurrent Neural Network, specifically a Long Short Term Memory network. In a previous project, I had created a Bidirection LSTM using the Keras package from tensorflow, so with some additional research I found how to implement a Seq2Seq model using Keras.\n",
        "\n",
        "The biggest problem I had was finding a way to prepare the data so that I could feed the training data into a model made for human language and allow it to predict its outcome. So to solve this, I decided to try and structure the data like a sentence. I treated variables, numbers, and logical operators like words in a sentence, and placed spaces between each.\n",
        "\n",
        "Knowing that all the polynomials were single variable polynomials, I decided to replace all variables within the data with \"x\" in order to keep some consistency, which would assist greatly in training."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NLP Polynomial Expansion",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}